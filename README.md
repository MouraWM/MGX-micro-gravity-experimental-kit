# Micro Gravity Experimental kit

An Open-Source Platform for Accessible Space Science Experiments.

![](https://github.com/MouraWM/MGX-micro-gravity-experimental-kit/images/wd.jpg)

![](https://img.shields.io/github/stars/MouraWM/MGX-micro-gravity-experimental-kit) ![](https://img.shields.io/github/forks/MouraWM/MGX-micro-gravity-experimental-kit.svg) ![](https://img.shields.io/github/release/MouraWM/MGX-micro-gravity-experimental-kit.svg) ![](https://img.shields.io/github/issues/MouraWM/MGX-micro-gravity-experimental-kit.svg) ![](https://img.shields.io/github/bower/MouraWM/MGX-micro-gravity-experimental-kit.svg)

## Features

This work aims to develop the Micro Gravity Experimental kit (MGX), a multipurpose experimental platform that can serve various experimental purposes. A highly active area in micro gravity research is biological investigations and measurements. For instance, analyzing biological images in micro gravity is important to understanding the effects of this environment on living organisms. Therefore, having a platform that allows for the development of an automated system to capture, process, and analyze biological images in real-time during micro gravity experiments would be an example of what the proposed system in this work could achieve. This system would not be limited to this application but could also serve as an instrument for research in other fields such as ionospheric physics, materials science, and space technologies. 



## Architecture

In MGX Architecture, the expected output is a representation in a lower level of abstraction, such as a block diagram, lowering the abstraction level of the MGX module facilitated the test and validation of the module requirement by incremental integration. Furthermore, NASA 8739.23A declares that an architecture review based on the block diagram could ensure that all the requirements have been addressed. Likewise, DO-254 states that using a functional block diagram as a high-level design concept helps to assess the potential for the resulting design implementation to meet the requirements.
Figure 1 represents the MGX internal architecture, where the main controller (Jetson Orin Nano) connects to the 14 main parts of the MGX. Thus, a picture of what is contained inside the MGX can be observed, and any deviation from the initial project can be corrected.

![](https://github.com/MouraWM/MGX-micro-gravity-experimental-kit/blob/main/images/Fig01.png)

> Figure 1. MGX architecture



## Hardware Design Detail

More detailed hardware can be developed based on the architecture presented in Figure 1. A printed circuit board can be developed from the detailed hardware, providing ways to build a physical model of the MGX. Each of the MGX's 14 features is intended to provide the kit's user with ways to implement its own experiments. Temperature, pressure, and IMU are common measures used in microgravity missions. Thus, they are integrated parts of the MGX. However, if another phenomenon needs to be measured, the MGX offers other ways to connect with the desired sensor. For example, an accelerometer of different ranges provided by MGX is needed. It can be connected through the I2C or SPI bus, or if the output is analog, it can be connected to one of the 32 analog channels. Such flexibility gives freedom to the user to deploy a variety of experiments.
If the payload is recovered, the M2 NVMe bus can be connected to an SSD data storage that can be used to store the experiment data; however, if there is no recovery or the recovery fails, it is possible to use the serial channel connected to a PCM and transmitter to send the data over the telemetry channel. 

How some experiments have cameras to observe their behavior, the MGX offers two camera connections to observe different angles of the experiment or even different experiments. The Jetson board offers connections up to 4K resolution at 30 fps.  This configuration delivers a good-quality image, allowing the user to study the micro gravity phenomenon more clearly. Moreover, some experiments used in micro gravity need actuators. The MGX offers a dedicated 4 Ampere current output to provide such a feature. Some experiments will need an oven or a cooler, and such experiments demand high currents to operate properly.

The UARTs are intended to communicate with other experiments, or to communicate with the MGX to configure it. However, the signal can be degraded when not properly referenced (grounded). To avoid this problem, the MGX could benefit from commercial integrated circuits to easily the task of isolation. For example, the integrated circuit MAX33250E can be used. Thus, it provides an isolated UART 1 that complies with the RS-232 standard. Figure 2 shows the Illustration of electronic sensor capabilities inside the experiment module, including I2C, analog sensors, UART, and 4K camera inputs, besides actuators inside the MGX. 

![](https://github.com/MouraWM/MGX-micro-gravity-experimental-kit/blob/main/images/Fig02.png)

> Figure 2.  Illustration of electronic sensor capabilities inside the experiment module, including I2C, analog sensors, UART, and 4K camera inputs, besides actuators.



## Software Implementation and Functionality

The project repository includes routines for reading camera images and sensor data, specifically designed to run on NVIDIA Linux for Tegra (L4T), based on Ubuntu Linux. The MGX’s operational codes were developed in C++, while machine learning routines were implemented in Python. In addition to these data and image acquisition routines, there are also routines for data compression using H.265, based on [66]. Machine learning plays an important role in automating and enhancing accuracy in data analysis, making it particularly valuable for research conducted in microgravity environments. The behavior of fluids, materials, and biological systems can significantly differ from that observed on Earth, necessitating precise and real-time analysis for scientific advancements. The Jetson Nano platform, used in the MGX, enables efficient parallel processing, facilitating rapid and accurate analysis of large data volumes. Implementing ML algorithms on the Jetson Nano involves some stages, from data collection and preprocessing to real-time analysis and decision-making. Equipped with high-resolution sensors and cameras, the Jetson Nano may continuously collect data during microgravity experiments, including high-resolution images and sensor data on temperature, pressure, and IMU. The first step is data preprocessing to ensure it is suitable for analysis. Image data can be preprocessed using libraries like OpenCV and PyTorch. This includes image normalization, noise removal, and transforming images into a format compatible with deep learning models. While deep learning model training typically occurs on powerful workstations or GPU clusters, the Jetson Nano can handle smaller training tasks or fine-tuning pre-trained models. Models like Convolutional Neural Networks (CNNs),
U-Net, and Long Short-Term Memory (LSTM) networks can be trained using frameworks such as TensorFlow or PyTorch. After training, ML models can be deployed on the Jetson Nano for real-time analysis during suborbital flights. Object detection and classification in images are essential for many studies. Deep learning algorithms like CNNs can identify and classify particles, microorganisms, or cells in high-resolution images. For fluid experiments, image segmentation using the DeepLabv3+ model can identify and track suspended particles, aiding in understanding phenomena like droplet coalescence or
bubble formation. Image segmentation might be interesting for isolating and analyzing different components within an image. In microgravity, this capability applies to various experimental contexts. For instance, in biological studies, U-Net can segment different types of tissue or cells, enabling detailed analysis of cell morphology and interactions in microgravity. These algorithms can be implemented in the MGX, processing real-time images and
providing immediate results to researchers. Figure 3 shows the process of segmenting cells using U-Net architecture. Tracking movements in microgravity might be important for understanding the dynamic behavior of particles and cells. In this case, deep learning algorithms combining
CNNs with LSTM could track the movement of microparticles in fluids, providing detailed data on particle trajectories and velocities. This approach is particularly useful in cellular biology experiments, revealing how cells move and interact in a microgravity environment.
Pattern recognition in image data is another powerful ML application in the MGX. Algorithms can detect abnormal patterns or identify specific structures, indicating interesting phenomena or potential problems. For example, deep learning models like YOLO (You Only Look Once) can recognize specific structures in protein crystallization experiments, providing precise data on crystal formation and behavior in microgravity. One of the most significant advantages of using ML in the MGX is automation. ML systems can process and analyze data in real time, allowing immediate experiment adjustments and accelerating results acquisition. Post-flight, automated analysis of large image data volumes can expedite results and insights, saving time and resources for researchers. Modeling and simulation using ML help predict how different experimental conditions affect outcomes, aiding in planning future experiments. ML models can simulate the effects of various microgravity conditions on experimental results, optimizing experiments before
flight. Learning algorithms can predict outcomes based on historical data, guiding research and increasing efficiency. This is especially useful in complex experiments, where precise predictions can help identify optimal conditions and reduce the need for repeated trials. Integrating ML with control systems allows for more precise and autonomous experimentation. Computer vision systems integrated with ML can provide automatic feedback to adjust experimental parameters in real time, enhancing accuracy. ML algorithms can control experimental devices like robotic manipulators, ensuring precise and efficient execution based on real-time image analysis. This is particularly beneficial in experiments requiring continuous adjustments, significantly improving data quality and reducing researcher workload.
To illustrate MGX’s ML capabilities, consider practical examples. One hypothetical application is using ML to monitor sperm motility in microgravity experiments. The study byshowed that sperm motility can be affected by simulated microgravity conditions.
By analyzing videos of moving sperm, ML algorithms can quantify sperm cell speed and trajectory, providing valuable data on how microgravity impacts reproduction and cellular health. Implementing such analysis on the Jetson Nano enables real-time monitoring and adjustments during space missions, ensuring precise and actionable data collection. Moreover, ML can analyze cellular respiration and protein content under microgravity conditions. Deep learning algorithms can analyze polarographic data, identifying oxygen consumption patterns associated with mitochondrial activity changes in response to microgravity. Similarly, computer vision algorithms can automate Western blot analysis for protein content, facilitating precise quantification of proteins involved in cellular reI2Cration and cytoskeletal structure. This automation, powered by the MGX, significantly enhances the efficiency and accuracy of biological experiments in microgravity, providing critical insights into cellular functions and adaptations in space.



![](https://github.com/MouraWM/MGX-micro-gravity-experimental-kit/blob/main/images/Fig03.png)

> Figure 3.  Diagram of U-Net architecture illustrating the process of segmenting cells in biological tissue images.
